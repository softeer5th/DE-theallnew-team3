import json
import openai
import pandas as pd
import glob

from dotenv import load_dotenv
import os

API_KEY = os.getenv("OPENAI_KEY")

# .env íŒŒì¼ í™œì„±í™”
load_dotenv()

# OpenAI API í‚¤ ì„¤ì • (ë³¸ì¸ì˜ í‚¤ë¡œ ë³€ê²½í•´ì•¼ í•¨)
client = openai.OpenAI(api_key=API_KEY)
# ë°°ì¹˜ í¬ê¸° ì„¤ì • (100ê°œì”© API í˜¸ì¶œ)
BATCH_SIZE = 20


def analyze_comments_batch(comments):
    """ì—¬ëŸ¬ ê°œì˜ ì½”ë©˜íŠ¸ë¥¼ í•œ ë²ˆì— ë¶„ì„í•˜ëŠ” ë°°ì¹˜ API í˜¸ì¶œ"""

    formatted_comments = "\n".join(
        [f"{i+1}. {comment}" for i, comment in enumerate(comments)]
    )

    prompt = f"""
    ì•„ë˜ ìë™ì°¨ ê´€ë ¨ ì½”ë©˜íŠ¸ë“¤ì˜ ê°ì„±ì„ ë¶„ì„í•˜ê³  ì£¼ì œë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”:

    {formatted_comments}

    ê°ì„±ê³¼ ì£¼ì œì˜ ì‘ë‹µ í˜•ì‹ì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •í•´ì£¼ì„¸ìš”
    - ê°ì„±: positive / negative / neutral  
    - ì£¼ì œ: ë””ìì¸ / ê¸°ëŠ¥ / ì‹ ë¢°ì„± / ê¸°íƒ€  

    ê²°ê³¼ëŠ” í•­ìƒ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:  
    1. ê°ì„±: [ê°ì„±], ì£¼ì œ: [ì£¼ì œ]  
    2. ê°ì„±: [ê°ì„±], ì£¼ì œ: [ì£¼ì œ]  
    ...
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "You are an expert at analyzing car-related comments.",
            },
            {"role": "user", "content": prompt},
        ],
        max_tokens=500,
    )

    result_text = response.choices[0].message.content.strip()

    results = []
    lines = result_text.split("\n")
    for i, line in enumerate(lines):
        try:
            sentiment = line.split("ê°ì„±:")[1].split(",")[0].strip()
            topic = line.split("ì£¼ì œ:")[1].strip()
            results.append(
                {"comment": comments[i], "sentiment": sentiment, "topic": topic}
            )
        except Exception as e:
            print(f"íŒŒì‹± ì˜¤ë¥˜: {e}, ì›ë³¸ ì‘ë‹µ: {line}")
            results.append(
                {"comment": comments[i], "sentiment": "error", "topic": "error"}
            )

    return results


def transform_llm(input_date, car_name):

    # OpenAI API í‚¤ ì„¤ì • (ë³¸ì¸ì˜ í‚¤ë¡œ ë³€ê²½í•´ì•¼ í•¨)
    client = openai.OpenAI(api_key=API_KEY)
    # ë°°ì¹˜ í¬ê¸° ì„¤ì • (100ê°œì”© API í˜¸ì¶œ)
    BATCH_SIZE = 20

    # ğŸ”¹ CSV íŒŒì¼ ì½ê¸°

    json_files = glob.glob(f"data/transformed/part-*.json")
    frames = [pd.read_json(json_file, lines=True) for json_file in json_files]
    df = pd.concat(frames)

    # ğŸ”¹ NaN ê°’ì„ 0ìœ¼ë¡œ ë³€ê²½
    df = df.fillna(0)

    # ğŸ”¹ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
    comments = df["text"].tolist()

    # ğŸ”¹ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    results = []

    # ğŸ”¹ ë°°ì¹˜ë¡œ API í˜¸ì¶œ
    for i in range(0, len(comments), BATCH_SIZE):
        batch = comments[i : i + BATCH_SIZE]
        batch_results = analyze_comments_batch(batch)
        results.extend(batch_results)
        print(f"{i + len(batch)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")

    # ğŸ”¹ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ í›„ ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
    analysis_df = pd.DataFrame(results)
    df["sentiment"] = analysis_df["sentiment"]
    df["topic"] = analysis_df["topic"]

    # ğŸ”¹ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥
    csv_output = f"data/youtube_{input_date}_{car_name}_llm.csv"
    df.to_csv(csv_output, index=False, encoding="utf-8-sig")

    # ğŸ”¹ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
    print(f"ë¶„ì„ ê²°ê³¼ê°€ CSV íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_output}")


# 10:34 ì‹œì‘ 1600ê°œ ë°°ì¹˜ 100ê°œ  - 3ë¶„

# 10:56 ì‹œì‘ 400ê°œ ë°°ì¹˜ 20,
